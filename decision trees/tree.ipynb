{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['young', 'young', 'young', 'young', 'young', 'young', 'young', 'young', 'pre', 'pre', 'pre', 'pre', 'pre', 'pre', 'pre', 'pre', 'presbyopic', 'presbyopic', 'presbyopic', 'presbyopic', 'presbyopic', 'presbyopic', 'presbyopic', 'presbyopic']\n",
      "['myope', 'myope', 'myope', 'myope', 'hyper', 'hyper', 'hyper', 'hyper', 'myope', 'myope', 'myope', 'myope', 'hyper', 'hyper', 'hyper', 'hyper', 'myope', 'myope', 'myope', 'myope', 'hyper', 'hyper', 'hyper', 'hyper']\n",
      "['no', 'no', 'yes', 'yes', 'no', 'no', 'yes', 'yes', 'no', 'no', 'yes', 'yes', 'no', 'no', 'yes', 'yes', 'no', 'no', 'yes', 'yes', 'no', 'no', 'yes', 'yes']\n",
      "['reduced', 'normal', 'reduced', 'normal', 'reduced', 'normal', 'reduced', 'normal', 'reduced', 'normal', 'reduced', 'normal', 'reduced', 'normal', 'reduced', 'normal', 'reduced', 'normal', 'reduced', 'normal', 'reduced', 'normal', 'reduced', 'normal']\n",
      "['young', 'young', 'young', 'young', 'pre', 'pre', 'pre', 'pre', 'presbyopic', 'presbyopic', 'presbyopic', 'presbyopic']\n",
      "['myope', 'myope', 'hyper', 'hyper', 'myope', 'myope', 'hyper', 'hyper', 'myope', 'myope', 'hyper', 'hyper']\n",
      "['no', 'yes', 'no', 'yes', 'no', 'yes', 'no', 'yes', 'no', 'yes', 'no', 'yes']\n",
      "['young', 'young', 'pre', 'pre', 'presbyopic', 'presbyopic']\n",
      "['myope', 'hyper', 'myope', 'hyper', 'myope', 'hyper']\n",
      "['young', 'pre', 'presbyopic']\n",
      "['young', 'young', 'pre', 'pre', 'presbyopic', 'presbyopic']\n",
      "['myope', 'hyper', 'myope', 'hyper', 'myope', 'hyper']\n",
      "['myope', 'hyper']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'tearRate': {'normal': {'astigmatic': {'no': {'age': {'pre': 'soft',\n",
       "      'presbyopic': {'prescript': {'hyper': 'soft', 'myope': 'no lenses'}},\n",
       "      'young': 'soft'}},\n",
       "    'yes': {'prescript': {'hyper': {'age': {'pre': 'no lenses',\n",
       "        'presbyopic': 'no lenses',\n",
       "        'young': 'hard'}},\n",
       "      'myope': 'hard'}}}},\n",
       "  'reduced': 'no lenses'}}"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from math import log\n",
    "import numpy as np\n",
    "\n",
    "def create_data_set():\n",
    "    dataset = [[1, 1, 'yes'], \n",
    "               [1, 1, 'yes'],\n",
    "               [1, 0, 'no'], \n",
    "               [0, 1, 'no'], \n",
    "               [0, 1, 'no']]\n",
    "    labels = ['no surface', 'flippers']\n",
    "    return dataset, labels\n",
    "\n",
    "def shannon_entropy(dataset):\n",
    "    n = len(dataset)\n",
    "    labelcounts = {}\n",
    "    \n",
    "    #统计每一种label的个数\n",
    "    for feature in dataset:\n",
    "        current_label = feature[-1]\n",
    "        if current_label not in labelcounts.keys():\n",
    "            labelcounts[current_label] = 0\n",
    "        labelcounts[current_label] += 1\n",
    "        \n",
    "    #将每一种label按信息熵公式计算并求和\n",
    "    entropy = 0.0\n",
    "    for key in labelcounts:\n",
    "        prop = float(labelcounts[key]) / n\n",
    "        entropy -= prop * log(prop, 2)\n",
    "    return entropy\n",
    "\n",
    "#对某个属性（axis），按属性的值将原数据划分得到一个子集数据\n",
    "#要将属性本身的值去掉，取改值下其他所有属性和标签值\n",
    "def split_data(dataset, axis, value):\n",
    "    restdataset = []\n",
    "    for feature in dataset:     \n",
    "        if feature[axis] == value:\n",
    "            reduced = feature[:axis]\n",
    "            reduced.extend(feature[axis+1:])\n",
    "            restdataset.append(reduced)\n",
    "#     print(\"split++++++++++++++\")\n",
    "#     print(restdataset)\n",
    "    return restdataset\n",
    "        \n",
    "def choose_best_feature_to_split(dataset):\n",
    "    #获取属性个数\n",
    "    feature_number = len(dataset[0]) -1\n",
    "    base_entropy = shannon_entropy(dataset)\n",
    "    best_info_gain = 0.0\n",
    "    best_feature = -1\n",
    "    \n",
    "    #每个属性计算一次信息增益\n",
    "    for i in range(feature_number):\n",
    "        #取该属性所有值放入list\n",
    "        feature_list = [example[i] for example in dataset]\n",
    "        print (feature_list)\n",
    "        #唯一化属性值\n",
    "        uniquevals = set(feature_list)\n",
    "        feature_entropy = 0.0\n",
    "        #对每个值，划分数据后，计算信息熵\n",
    "        for val in uniquevals:\n",
    "            subdataset = split_data(dataset, i, val)\n",
    "            prob = len(subdataset) / float(len(dataset))\n",
    "            feature_entropy += prob * shannon_entropy(subdataset)\n",
    "        #计算信息增益，父信息熵 - 按改属性分裂后信息熵\n",
    "        info_gain = base_entropy - feature_entropy\n",
    "        \n",
    "        #获取大的信息增益及属性\n",
    "        if info_gain > best_info_gain:\n",
    "            best_info_gain = info_gain\n",
    "            best_feature = i\n",
    "    return best_feature\n",
    "\n",
    "def majority_cnt(classlist):\n",
    "    class_count = {}\n",
    "    #按class 统计每一种的个数，降序排列，取第一个即票数最多那类的数量\n",
    "    for vote in classlist:\n",
    "        if vote not in class_count:\n",
    "            class_count[vote] = 0\n",
    "        class_count[vote] += 1\n",
    "        sorted_class_count = sorted(class_count.iteritems(), \n",
    "                             key=operator.itemgetter(1), \n",
    "                             reverse=True)\n",
    "    return sorted_class_count[0][0]\n",
    "\n",
    "def create_tree(dataset, labels):\n",
    "    #获取标签列表\n",
    "    classlist = [example[-1] for example in dataset]\n",
    "    #所有class labels相同，停止递归，\n",
    "    if classlist.count(classlist[0]) == len(classlist):\n",
    "        return classlist[0]\n",
    "    #没有属性用于split了，停止递归，投票决定\n",
    "    if len(dataset) == 1:\n",
    "        return majority_cnt(classlist)\n",
    "    \n",
    "    #找出split的feature\n",
    "    bestfeature = choose_best_feature_to_split(dataset)\n",
    "    bestfeaturelabel = labels[bestfeature]\n",
    "    \n",
    "    #创建空树\n",
    "    myTree = {bestfeaturelabel:{}}\n",
    "    #从标签列表去掉最佳属性的位置\n",
    "    del(labels[bestfeature])\n",
    "    featurevalues = [example[bestfeature] for example in dataset]\n",
    "    uniquevals = set(featurevalues)\n",
    "    #遍历属性的每一种值，递归建树\n",
    "    for val in uniquevals:\n",
    "        sublabels = labels[:]\n",
    "        myTree[bestfeaturelabel][val] = create_tree(split_data(dataset, bestfeature, val), sublabels)\n",
    "    return myTree\n",
    "   \n",
    "def classify(inputtree, featurelabels, testvector):\n",
    "    firstSides = list(inputtree.keys())\n",
    "    first_str = firstSides[0]\n",
    "    print(featurelabels)\n",
    "    second_dict = inputtree[first_str]\n",
    "    feature_index = featurelabels.index(first_str)\n",
    "    #遍历树中所有key，如果与待检测向量的值相同，看看不是dict类型，是表明未找到，继续找，否则返回类型\n",
    "    for key in second_dict.keys():\n",
    "        if testvector[feature_index] == key:\n",
    "            if type(second_dict[key]).__name__=='dict':\n",
    "                classlabel = classify(seconddict[key], featurelabels, testvector)\n",
    "            else:\n",
    "                classlabel = second_dict[key]\n",
    "    return classlabel\n",
    "  \n",
    "def storeTree(inputTree,filename):\n",
    "    import pickle\n",
    "    fw = open(filename,'w')\n",
    "    pickle.dump(inputTree,fw)\n",
    "    fw.close()\n",
    "\n",
    "def grabTree(filename):\n",
    "    import pickle\n",
    "    fr = open(filename)\n",
    "    return pickle.load(fr)\n",
    "\n",
    "# dataset,labels = create_data_set()\n",
    "# print(labels)\n",
    "# orig_labels = labels.copy()\n",
    "\n",
    "# split_data(dataset, 1, 1)\n",
    "# choose_best_feature_to_split(dataset)\n",
    "# myTree = create_tree(dataset, labels)\n",
    "# print(orig_labels)\n",
    "# classify(myTree,orig_labels,[1,1])\n",
    "# shannon_entropy(dataset)\n",
    "\n",
    "\n",
    "fr=open('lenses.txt')\n",
    "lenses=[inst.strip().split('\\t') for inst in fr.readlines()]\n",
    "lensesLabels=['age', 'prescript', 'astigmatic', 'tearRate']\n",
    "lensesTree = create_tree(lenses,lensesLabels)\n",
    "lensesTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
