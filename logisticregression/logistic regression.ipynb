{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "逻辑回归：多采用随机梯度下降法学习得到模型的最佳参数w（或者theta），本例中在学习过程中依据迭代次数来降低学习率，每次迭代学习，仅随机取一共样本参与学习。这种方法计算量小，需要内存小，速度快。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wupin\\AppData\\Roaming\\Python\\Python36\\site-packages\\ipykernel_launcher.py:26: RuntimeWarning: overflow encountered in exp\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the error rate of this test is: 0.373134\n",
      "the error rate of this test is: 0.328358\n",
      "the error rate of this test is: 0.358209\n",
      "the error rate of this test is: 0.313433\n",
      "the error rate of this test is: 0.298507\n",
      "the error rate of this test is: 0.343284\n",
      "the error rate of this test is: 0.328358\n",
      "the error rate of this test is: 0.373134\n",
      "the error rate of this test is: 0.358209\n",
      "the error rate of this test is: 0.268657\n",
      "the error rate of this test is: 0.343284\n",
      "after 10 iterations the average error rate is: 0.331343\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# def loadData(file):\n",
    "#     data = np.array(pd.read_csv(file))\n",
    "#     newdata = np.c_[np.ones(data.shape[0]), data]\n",
    "#     return newdata\n",
    "#     n,m = data.shape\n",
    "#     y = data[:, -1]\n",
    "#     X = data[:, :-1]\n",
    "#     return X, y, n, m-1\n",
    "\n",
    "def loadDataSet():\n",
    "    #准备数据和标签的空list\n",
    "    dataMat = []\n",
    "    labelMat = []\n",
    "    fr = open('data/testSet.txt')\n",
    "    for line in fr.readlines():\n",
    "        lineArr = line.strip().split()\n",
    "        dataMat.append([1.0, float(lineArr[0]), float(lineArr[1])])\n",
    "        labelMat.append(int(lineArr[2]))\n",
    "    return dataMat, labelMat\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1.0 / (1 + np.exp(-x))\n",
    "\n",
    "def gradAscent(dataMatIn, classLabels):\n",
    "    dataMatrix = np.array(dataMatIn)             #convert to NumPy array\n",
    "    labelMatrix = np.array(classLabels)          #convert to NumPy array\n",
    "    labelMatrix = labelMatrix.reshape((-1, 1))\n",
    "    m, n = dataMatrix.shape\n",
    "    alpha = 0.001\n",
    "    maxCycles = 500\n",
    "    weights = np.ones((n, 1))\n",
    "    for k in range(maxCycles):                       \n",
    "        h = sigmoid(np.dot(dataMatrix, weights))     #calculate hw(x*w)\n",
    "        error = (labelMatrix - h)                    #vector subtraction\n",
    "        weights = weights + alpha * np.dot(dataMatrix.T, error) \n",
    "    return weights\n",
    "\n",
    "def stocGradAscent0(dataMatIn, classLabels):\n",
    "    dataMatrix = np.array(dataMatIn)             #convert to NumPy array\n",
    "    labelMatrix = np.array(classLabels)          #convert to NumPy array\n",
    "    labelMatrix = labelMatrix.reshape((-1, 1))\n",
    "    m, n = np.shape(dataMatrix)\n",
    "    alpha = 0.01\n",
    "    weights = np.ones(n)   #initialize to all ones\n",
    "    #iterate m times, each time choose one sampe i to update weights\n",
    "    for i in range(m):\n",
    "        h = sigmoid(np.dot(dataMatrix[i], weights))\n",
    "        error = classLabels[i] - h\n",
    "        weights = weights + alpha * error * dataMatrix[i]\n",
    "    return weights\n",
    "\n",
    "def stocGradAscent1(dataMatIn, classLabels, numIter=150):\n",
    "    dataMatrix = np.array(dataMatIn)             #convert to NumPy array\n",
    "    labelMatrix = np.array(classLabels)          #convert to NumPy array\n",
    "    labelMatrix = labelMatrix.reshape((-1, 1))\n",
    "    m, n = np.shape(dataMatrix)\n",
    "    weights = np.ones(n)   #initialize to all ones\n",
    "    \n",
    "    #epoch numter times, each time, randomly choose a sample to update weights\n",
    "    for j in range(numIter):\n",
    "        dataIndex = list(range(m))\n",
    "        for i in range(m):\n",
    "            #decrease learning rate with iteration, will not go to zero by 0.0001\n",
    "            alpha = 4/(1.0+j+i)+0.0001    \n",
    "            randIndex = int(np.random.uniform(0, len(dataIndex)))\n",
    "            h = sigmoid(np.dot(dataMatrix[randIndex],weights))\n",
    "            error = classLabels[randIndex] - h\n",
    "            weights = weights + alpha * error * dataMatrix[randIndex]\n",
    "            del(dataIndex[randIndex])\n",
    "    return weights\n",
    "\n",
    "def plotBestFit(weights):\n",
    "    import matplotlib.pyplot as plt\n",
    "    %matplotlib inline\n",
    "    dataMatrix, labelMatrix = loadDataSet()\n",
    "    dataArr = np.array(dataMatrix)\n",
    "    n = np.shape(dataArr)[0]\n",
    "    xcord1 = []; ycord1 = []\n",
    "    xcord2 = []; ycord2 = []\n",
    "    for i in range(n):\n",
    "        if int(labelMatrix[i]) == 1:\n",
    "            xcord1.append(dataArr[i, 1]); ycord1.append(dataArr[i, 2])\n",
    "        else:\n",
    "            xcord2.append(dataArr[i, 1]); ycord2.append(dataArr[i, 2])\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.scatter(xcord1, ycord1, s=30, c='red', marker='s')\n",
    "    ax.scatter(xcord2, ycord2, s=30, c='green')\n",
    "    x = np.arange(-3.0, 3.0, 0.1)\n",
    "    y = (-weights[0]-weights[1]*x)/weights[2]\n",
    "    ax.plot(x,y.transpose())\n",
    "    plt.xlabel('X1'); plt.ylabel('X2')\n",
    "    plt.show()\n",
    "    \n",
    "def classifyVector(inX, weights):\n",
    "    #calculate the probability of input X\n",
    "    prob = sigmoid(np.dot(inX, weights))\n",
    "    if prob > 0.5: \n",
    "        return 1.0\n",
    "    else: \n",
    "        return 0.0\n",
    "\n",
    "def colicTest():\n",
    "    #load training data and test data\n",
    "    frTrain = open('data/horseColicTraining.txt'); frTest = open('data/horseColicTest.txt')\n",
    "    trainingSet = []; trainingLabels = []\n",
    "    for line in frTrain.readlines():\n",
    "        currLine = line.strip().split() #do not using split('\\t'), this will contain tab, space, return\n",
    "        lineArr = []\n",
    "        for i in range(21):\n",
    "            lineArr.append(float(currLine[i]))\n",
    "        trainingSet.append(lineArr)\n",
    "        trainingLabels.append(float(currLine[21]))\n",
    "    \n",
    "    #using stochastic gradient ascent to learn weights, epoch 1000\n",
    "    trainWeights = stocGradAscent1(np.array(trainingSet), trainingLabels, 1000)\n",
    "    errorCount = 0; numTestVec = 0.0\n",
    "    for line in frTest.readlines():\n",
    "        numTestVec += 1.0\n",
    "        #split by tab ,space or return\n",
    "        currLine = line.strip().split()\n",
    "        lineArr = []\n",
    "        for i in range(21):\n",
    "            lineArr.append(float(currLine[i]))\n",
    "        if int(classifyVector(np.array(lineArr), trainWeights)) != int(currLine[21]):\n",
    "            errorCount += 1\n",
    "    errorRate = (float(errorCount)/numTestVec)\n",
    "    print(\"the error rate of this test is: %f\" % errorRate)\n",
    "    return errorRate\n",
    "\n",
    "def multiTest():\n",
    "    numTests = 10; errorSum = 0.0\n",
    "    for k in range(numTests):\n",
    "        errorSum += colicTest()\n",
    "    print(\"after %d iterations the average error rate is: %f\" % (numTests, errorSum/float(numTests)))\n",
    "# def plotBestFit(w):\n",
    "#     import matplotlib.pyplot as plt\n",
    "#     data = loadData('data/testSet.csv')\n",
    "#     pos = data[np.where(data[:,-1] == 1)]\n",
    "#     neg = data[np.where(data[:,-1] == 0)]\n",
    "    \n",
    "#     fig = plt.figure()\n",
    "#     ax = fig.add_subplot(111)\n",
    "#     ax.scatter(pos[:,0], pos[:,1], s=30, c='red', marker='s')\n",
    "#     ax.scatter(neg[:,0], neg[:,1], s=30, c='g', marker='s')\n",
    "#     x = np.arange(-3.0, 3.0, 0.1)\n",
    "#     y = (-w[0]-w[1]*x)/w[2]\n",
    "#     ax.plot(x,y)\n",
    "#     plt.xlabel('X1')\n",
    "#     plt.ylabel('X2')\n",
    "#     plt.show()\n",
    "\n",
    "\n",
    "# data, label = loadDataSet()\n",
    "# weights = gradAscent(data, label)\n",
    "# plotBestFit(weights)\n",
    "# weights = stocGradAscent0(data, label)\n",
    "# plotBestFit(weights)\n",
    "# weights = stocGradAscent1(data, label)\n",
    "# plotBestFit(weights)\n",
    "\n",
    "colicTest()\n",
    "multiTest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
